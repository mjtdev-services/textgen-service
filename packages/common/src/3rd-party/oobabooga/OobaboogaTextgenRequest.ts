import type { OpenRouterMessage } from "../open-router/OpenRouterTextgenRequest";

export type OobaboogaTextgenRequest = Partial<{
  messages?: Readonly<OpenRouterMessage[]>;
  model: string;
  frequency_penalty: number;
  function_call: string;
  functions: unknown[];
  logit_bias: object;
  max_tokens: number;
  n: number;
  presence_penalty: number;
  // stop: string[];
  stream: boolean;
  temperature: number;
  top_p: number;
  user: string;
  mode: string;
  instruction_template: string;
  instruction_template_str: string;
  character: string;
  name2: string;
  context: string;
  greeting: string;
  name1: string;
  user_bio: string;
  chat_template_str: string;
  chat_instruct_command: string;
  continue_: boolean;
  preset: string;
  min_p: number;
  dynamic_temperature: boolean;
  dynatemp_low: number;
  dynatemp_high: number;
  dynatemp_exponent: number;
  smoothing_factor: number;
  smoothing_curve: number;
  top_k: number;
  repetition_penalty: number;
  repetition_penalty_range: number;
  typical_p: number;
  tfs: number;
  top_a: number;
  epsilon_cutoff: number;
  eta_cutoff: number;
  guidance_scale: number;
  negative_prompt: string;
  penalty_alpha: number;
  mirostat_mode: number;
  mirostat_tau: number;
  mirostat_eta: number;
  temperature_last: boolean;
  do_sample: boolean;
  seed: number;
  encoder_repetition_penalty: number;
  no_repeat_ngram_size: number;
  truncation_length: number;
  max_tokens_second: number;
  prompt_lookup_num_tokens: number;
  custom_token_bans: string;
  sampler_priority: string[];
  auto_max_new_tokens: boolean;
  ban_eos_token: boolean;
  add_bos_token: boolean;
  skip_special_tokens: boolean;
  grammar_string: string;
}>;
